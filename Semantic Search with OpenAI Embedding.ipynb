{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"execution":{}},"source":["<div id=\"singlestore-header\" style=\"display: flex; background-color: rgba(210, 255, 153, 0.25); padding: 5px;\">\n","    <div id=\"icon-image\" style=\"width: 90px; height: 90px;\">\n","        <img width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/header-icons/chart-network.png\" />\n","    </div>\n","    <div id=\"text\" style=\"padding: 5px; margin-left: 10px;\">\n","        <div id=\"badge\" style=\"display: inline-block; background-color: rgba(0, 0, 0, 0.15); border-radius: 4px; padding: 4px 8px; align-items: center; margin-top: 6px; margin-bottom: -2px; font-size: 80%\">SingleStore Notebooks</div>\n","        <h1 style=\"font-weight: 500; margin: 8px 0 0 4px;\">Semantic Search with OpenAI Embedding Creation</h1>\n","    </div>\n","</div>"]},{"attachments":{},"cell_type":"markdown","metadata":{"execution":{}},"source":["<div class=\"alert alert-block alert-warning\">\n","    <b class=\"fa fa-solid fa-exclamation-circle\"></b>\n","    <div>\n","        <p><b>Note</b></p>\n","        <p>This notebook can be run on a Free Starter Workspace. To create a Free Starter Workspace navigate to <tt>Start</tt> using the left nav. You can also use your existing Standard or Premium workspace with this Notebook.</p>\n","    </div>\n","</div>"]},{"attachments":{},"cell_type":"markdown","metadata":{"execution":{}},"source":["In this notebook, we will demonstrate an example of conducting semantic search on SingleStoreDB with SQL! Unlike traditional keyword-based search methods, semantic search algorithms take into account the relationships between words and their meanings, enabling them to deliver more accurate and relevant results – even when search terms are vague or ambiguous.\n","\n","SingleStoreDB’s built-in parallelization and Intel SIMD-based vector processing takes care of the heavy lifting involved in processing vector data. This allows your to run your ML algorithms right in your database extremely efficiently with just 2 lines of SQL!\n","\n","\n","In this example, we use Open AI embeddings API to create embeddings for our dataset and run semantic_search using dot_product vector matching function!"]},{"attachments":{},"cell_type":"markdown","metadata":{"execution":{}},"source":["## 1. Create a workspace in your workspace group\n","\n","S-00 is sufficient.\n","\n","<div class=\"alert alert-block alert-warning\">\n","    <b class=\"fa fa-solid fa-exclamation-circle\"></b>\n","    <div>\n","        <p><b>Action Required</b></p>\n","        <p> If you have a Free Starter Workspace deployed already, select the database from drop-down menu at the top of this notebook. It updates the <tt>connection_url</tt> to connect to that database.</p>\n","    </div>\n","</div>\n","\n","## 2. Create a Database named `semantic_search`"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-08-01T16:22:36.284343Z","iopub.status.busy":"2024-08-01T16:22:36.284040Z","iopub.status.idle":"2024-08-01T16:22:45.224376Z","shell.execute_reply":"2024-08-01T16:22:45.223729Z","shell.execute_reply.started":"2024-08-01T16:22:36.284317Z"},"language":"python","trusted":true},"outputs":[],"source":["shared_tier_check = %sql show variables like 'is_shared_tier'\n","if not shared_tier_check or shared_tier_check[0][1] == 'OFF':\n","    %sql DROP DATABASE IF EXISTS semantic_search;\n","    %sql CREATE DATABASE semantic_search;"]},{"attachments":{},"cell_type":"markdown","metadata":{"execution":{}},"source":["<div class=\"alert alert-block alert-warning\">\n","    <b class=\"fa fa-solid fa-exclamation-circle\"></b>\n","    <div>\n","        <p><b>Action Required</b></p>\n","        <p>Make sure to select the <tt>semantic_search</tt> database from the drop-down menu at the top of this notebook.\n","        It updates the <tt>connection_url</tt> which is used by the <tt>%%sql</tt> magic command and SQLAlchemy to make connections to the selected database.</p>\n","    </div>\n","</div>"]},{"attachments":{},"cell_type":"markdown","metadata":{"execution":{}},"source":["## 3. Install and import required libraries\n","\n","We will use the OpenAI embeddings API and will need to import the relevant dependencies accordingly."]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-08-01T16:22:45.228536Z","iopub.status.busy":"2024-08-01T16:22:45.226912Z","iopub.status.idle":"2024-08-01T16:22:50.444926Z","shell.execute_reply":"2024-08-01T16:22:50.442461Z","shell.execute_reply.started":"2024-08-01T16:22:45.228501Z"},"language":"python","trusted":true},"outputs":[],"source":["!pip3 install openai==1.3.3 requests --quiet\n","\n","import json\n","import requests"]},{"attachments":{},"cell_type":"markdown","metadata":{"execution":{}},"source":["## 4. Create an OpenAI account and get API connection details\n","\n","To vectorize and embed the employee reviews and query strings, we leverage OpenAI's embeddings API. To use this API, you will need an API key, which you can get [here](https://platform.openai.com/account/api-keys). You'll need to add a payment method to actually get vector embeddings using the API, though the charges are minimal for a small example like we present here."]},{"attachments":{},"cell_type":"markdown","metadata":{"execution":{}},"source":["<div class=\"alert alert-block alert-warning\">\n","    <b class=\"fa fa-solid fa-exclamation-circle\"></b>\n","    <div>\n","        <p><b>Action Required</b></p>\n","        <p>You will have to update your notebook's firewall settings to include <tt>*.*.openai.com</tt> in order to get embedddings from OpenAI APIS.</p>\n","    </div>\n","</div>"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-08-01T16:22:50.449910Z","iopub.status.busy":"2024-08-01T16:22:50.449126Z","iopub.status.idle":"2024-08-01T16:22:50.462498Z","shell.execute_reply":"2024-08-01T16:22:50.458513Z","shell.execute_reply.started":"2024-08-01T16:22:50.449874Z"},"language":"python","scrolled":true,"trusted":true},"outputs":[],"source":["import openai\n","\n","openai.api_key = ''"]},{"attachments":{},"cell_type":"markdown","metadata":{"execution":{}},"source":["## 5. Create a new table in your database called memories"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-08-01T16:23:26.447321Z","iopub.status.busy":"2024-08-01T16:23:26.446914Z","iopub.status.idle":"2024-08-01T16:23:26.950309Z","shell.execute_reply":"2024-08-01T16:23:26.949299Z","shell.execute_reply.started":"2024-08-01T16:23:26.447280Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/html":["<table>\n","    <thead>\n","        <tr>\n","        </tr>\n","    </thead>\n","    <tbody>\n","    </tbody>\n","</table>"],"text/plain":["++\n","||\n","++\n","++"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["%%sql\n","DROP TABLE IF EXISTS memories;\n","CREATE TABLE memories (\n","    date_memory VARCHAR(255),\n","    memory_title VARCHAR(255),\n","    location VARCHAR(255),\n","    memory TEXT\n",");"]},{"attachments":{},"cell_type":"markdown","metadata":{"execution":{}},"source":["## 6. Import our sample data into your table\n","\n","This dataset has memories left by Ania Kubow."]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-08-01T16:24:33.937341Z","iopub.status.busy":"2024-08-01T16:24:33.936957Z","iopub.status.idle":"2024-08-01T16:24:33.946731Z","shell.execute_reply":"2024-08-01T16:24:33.945968Z","shell.execute_reply.started":"2024-08-01T16:24:33.937311Z"},"language":"python","trusted":true},"outputs":[],"source":["url = 'https://raw.githubusercontent.com/kubowania/memories/main/memories.sql'"]},{"attachments":{},"cell_type":"markdown","metadata":{"execution":{}},"source":["Note that we are using the `%sql` magic command here to run a query against the currently\n","selected database."]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-08-01T16:24:37.396585Z","iopub.status.busy":"2024-08-01T16:24:37.396186Z","iopub.status.idle":"2024-08-01T16:24:37.778619Z","shell.execute_reply":"2024-08-01T16:24:37.777672Z","shell.execute_reply.started":"2024-08-01T16:24:37.396546Z"},"language":"python","trusted":true},"outputs":[],"source":["for query in [x for x in requests.get(url).text.split('\\n') if x.strip()]:\n","     %sql {{query}}"]},{"attachments":{},"cell_type":"markdown","metadata":{"execution":{}},"source":["## 7. Add vector embeddings for each memory\n","\n","To embed the memories in our SingleStoreDB database, we iterate through each row in the table, make a call to OpenAI’s embeddings API with the text in the memories field and update the new column called embeddings for each entry."]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-08-01T16:25:53.694385Z","iopub.status.busy":"2024-08-01T16:25:53.693940Z","iopub.status.idle":"2024-08-01T16:25:55.413793Z","shell.execute_reply":"2024-08-01T16:25:55.413101Z","shell.execute_reply.started":"2024-08-01T16:25:53.694346Z"},"language":"python","trusted":true},"outputs":[],"source":["%sql ALTER TABLE memories ADD embeddings BLOB;\n","\n","from typing import List\n","\n","memories = %sql SELECT memory FROM memories;\n","memories = [x.memory for x in memories]\n","\n","def get_embeddings(inputs: List[str], model: str = 'text-embedding-ada-002') -> List[str]:\n","    \"\"\"Return list of embeddings.\"\"\"\n","    return [x.embedding for x in openai.embeddings.create(input=inputs, model=model).data]\n","\n","embeddings = get_embeddings(memories)\n","\n","for embedding, memory in zip(embeddings, memories):\n","    %sql UPDATE memories SET embeddings = JSON_ARRAY_PACK('{{json.dumps(embedding)}}') WHERE memory='{{memory}}';"]},{"attachments":{},"cell_type":"markdown","metadata":{"execution":{}},"source":["## 8. Run the semantic search algorithm with just one line of SQL\n","\n","We will utilize SingleStoreDB's distributed architecture to efficiently compute the dot product of the input string (stored in searchstring) with each entry in the database and return the top 5 memories with the highest dot product score. Each vector is normalized to length 1, hence the dot product function essentially computes the cosine similarity between two vectors – an appropriate nearness metric. SingleStoreDB makes this extremely fast because it compiles queries to machine code and runs dot_product using SIMD instructions."]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-08-01T16:26:30.075942Z","iopub.status.busy":"2024-08-01T16:26:30.075553Z","iopub.status.idle":"2024-08-01T16:26:32.371056Z","shell.execute_reply":"2024-08-01T16:26:32.364770Z","shell.execute_reply.started":"2024-08-01T16:26:30.075912Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Please enter a search string:  google\n"]},{"name":"stdout","output_type":"stream","text":["\n","1: As speaker at the Google Developer event in London, I was able to share my experiences in the field. Score: 0.8052330613136292\n","\n","2: Microsoft Pitch day was an incredible opportunity to meet some amazing minds and see what they were up to. Score: 0.7580590844154358\n","\n","3: It was an honour to visit the United Nations in Geneva and hear pitches from all the Huawei competition finalists. Score: 0.7573343515396118\n","\n","4: A new chef has joined our Homebrew Coffee Shop team. They have already prepared an amazing menu of sandwiches and bagels. Score: 0.7570070624351501\n","\n","5: Today I opened by coffee shop for remote workers! It is called Homebrew as a nod to all my fellow Developers out there. Score: 0.7546314001083374\n","\n"]}],"source":["searchstring = input('Please enter a search string: ')\n","\n","search_embedding = json.dumps(get_embeddings([searchstring])[0])\n","\n","results = %sql SELECT memory, DOT_PRODUCT(embeddings, JSON_ARRAY_PACK('{{search_embedding}}')) AS score FROM memories ORDER BY score DESC LIMIT 5;\n","\n","print()\n","for i, res in enumerate(results):\n","    print(f'{i + 1}: {res.memory} Score: {res.score}\\n')"]},{"attachments":{},"cell_type":"markdown","metadata":{"execution":{}},"source":["## 9. Clean up"]},{"attachments":{},"cell_type":"markdown","metadata":{"execution":{}},"source":["<div class=\"alert alert-block alert-warning\">\n","    <b class=\"fa fa-solid fa-exclamation-circle\"></b>\n","    <div>\n","        <p><b>Action Required</b></p>\n","        <p> If you created a new database in your Standard or Premium Workspace, you can drop the database by running the cell below. Note: this will not drop your database for Free Starter Workspaces. To drop a Free Starter Workspace, terminate the Workspace using the UI. </p>\n","    </div>\n","</div>"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{},"language":"python"},"outputs":[],"source":["shared_tier_check = %sql show variables like 'is_shared_tier'\n","if not shared_tier_check or shared_tier_check[0][1] == 'OFF':\n","    %sql DROP DATABASE IF EXISTS semantic_search;"]},{"attachments":{},"cell_type":"markdown","metadata":{"execution":{}},"source":["<div id=\"singlestore-footer\" style=\"background-color: rgba(194, 193, 199, 0.25); height:2px; margin-bottom:10px\"></div>\n","<div><img src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/singlestore-logo-grey.png\" style=\"padding: 0px; margin: 0px; height: 24px\"/></div>"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"singlestore_cell_default_language":"python","singlestore_connection":{"connectionID":"af395f19-59df-40d8-9ccc-af847e546c54","defaultDatabase":"semantic_search"},"singlestore_row_limit":300},"nbformat":4,"nbformat_minor":5}
